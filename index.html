
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python package for enhancing the spatial resolution of Sentinel-2 satellite images to 2.5 meters.">
      
      
        <meta name="author" content="IPL-UV">
      
      
        <link rel="canonical" href="https://ipl-uv.github.io/supers2/index.html">
      
      <link rel="icon" href="assets/images/logo_ss2.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.2.16">
    
    
      
        <title>Index - SuperS2</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.1c3799f8.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.cc9b2e1e.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="assets/style.css">
    
    <script>__md_scope=new URL(".",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="#d49f0c" data-md-color-accent="#d49f0c">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="SuperS2" class="md-header__button md-logo" aria-label="SuperS2" data-md-component="logo">
      
  <img src="assets/images/logo_ss2.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SuperS2
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Index
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="#d49f0c" data-md-color-accent="#d49f0c"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="#201357" data-md-color-accent="white"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/IPL-UV/supers2" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    supers2
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="index.html" class="md-tabs__link md-tabs__link--active">
        Home
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="SuperS2" class="md-nav__button md-logo" aria-label="SuperS2" data-md-component="logo">
      
  <img src="assets/images/logo_ss2.png" alt="logo">

    </a>
    SuperS2
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/IPL-UV/supers2" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    supers2
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index md-nav__link--active">
          <a href="index.html">Home</a>
          
            <label for="__nav_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Home" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Home
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="CONTRIBUTING.html" class="md-nav__link">
        Contributing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="CHANGELOG.html" class="md-nav__link">
        Changelog
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="CODE_OF_CONDUCT.html" class="md-nav__link">
        Code of conduct
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview üìä
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    Installation ‚öôÔ∏è
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use" class="md-nav__link">
    How to use üõ†Ô∏è
  </a>
  
    <nav class="md-nav" aria-label="How to use üõ†Ô∏è">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-libraries" class="md-nav__link">
    Load libraries
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#download-sentinel-2-l2a-cube" class="md-nav__link">
    Download Sentinel-2 L2A cube
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-the-data-cpu-and-gpu-usage" class="md-nav__link">
    Prepare the data (CPU and GPU usage)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#default-model-setup" class="md-nav__link">
    Default model setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuring-model" class="md-nav__link">
    Configuring Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#available-models" class="md-nav__link">
    Available Models:
  </a>
  
    <nav class="md-nav" aria-label="Available Models:">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cnn-models" class="md-nav__link">
    1. CNN Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-swin-models" class="md-nav__link">
    2. SWIN Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-mamba-models" class="md-nav__link">
    3. MAMBA Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-diffusion-model" class="md-nav__link">
    4. Diffusion Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-simple-models-bilinear-and-bicubic" class="md-nav__link">
    5. Simple Models (Bilinear and Bicubic)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#apply-spatial-resolution-enhancement" class="md-nav__link">
    Apply spatial resolution enhancement
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predict-only-rgbnir-bands" class="md-nav__link">
    Predict only RGBNIR bands üåç
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#estimate-the-uncertainty-of-the-model" class="md-nav__link">
    Estimate the uncertainty of the model üìä
  </a>
  
    <nav class="md-nav" aria-label="Estimate the uncertainty of the model üìä">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#estimate-the-local-attention-map-of-the-model" class="md-nav__link">
    Estimate the Local Attention Map of the model üìä
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#use-the-opensr-test-and-supers2-to-analyze-the-hallucination-pixels" class="md-nav__link">
    Use the opensr-test and supers2 to analyze the hallucination pixels üìä
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/IPL-UV/supers2/edit/master/docs/README.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="_1"></h1>
<p align="center">
  <img src="assets/images/logo_ss2.png" width="30%">
</p>

<p align="center">
   <em>A Python package for enhancing the spatial resolution of Sentinel-2 satellite images up to 2.5 meters</em> üöÄ
</p>

<p align="center">
<a href='https://pypi.python.org/pypi/supers2'>
    <img src='https://img.shields.io/pypi/v/supers2.svg' alt='PyPI' />
</a>
<a href="https://opensource.org/licenses/MIT" target="_blank">
    <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License">
</a>
<a href="https://github.com/psf/black" target="_blank">
    <img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Black">
</a>
<a href="https://pycqa.github.io/isort/" target="_blank">
    <img src="https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336" alt="isort">
</a>
<a href="https://colab.research.google.com/drive/1TD014aY145q1reKN644egUtIM6tIx9vH?usp=sharing" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
</p>

<hr />
<p><strong>GitHub</strong>: <a href="https://github.com/IPL-UV/supers2">https://github.com/IPL-UV/supers2</a> üåê</p>
<p><strong>PyPI</strong>: <a href="https://pypi.org/project/supers2/">https://pypi.org/project/supers2/</a> üõ†Ô∏è</p>
<hr />
<h2 id="table-of-contents"><strong>Table of Contents</strong></h2>
<ul>
<li><a href="#overview-"><strong>Overview</strong> üìä</a></li>
<li><a href="#installation-"><strong>Installation</strong> ‚öôÔ∏è</a></li>
<li><a href="#how-to-use-"><strong>How to use</strong> üõ†Ô∏è</a><ul>
<li><a href="#load-libraries"><strong>Load libraries</strong></a></li>
<li><a href="#download-sentinel-2-l2a-cube"><strong>Download Sentinel-2 L2A cube</strong></a></li>
<li><a href="#prepare-the-data-cpu-and-gpu-usage"><strong>Prepare the data (CPU and GPU usage)</strong></a></li>
<li><a href="#default-model-setup"><strong>Default model setup</strong></a></li>
<li><a href="#configuring-the-spatial-resolution-enhancement-model"><strong>Configuring the Spatial Resolution Enhancement Model</strong></a></li>
<li><a href="#available-models"><strong>Available Models:</strong></a><ul>
<li><a href="#1-cnn-models"><strong>1. CNN Models</strong></a></li>
<li><a href="#2-swin-models"><strong>2. SWIN Models</strong></a></li>
<li><a href="#3-mamba-models"><strong>3. MAMBA Models</strong></a></li>
<li><a href="#4-diffusion-model"><strong>4. Diffusion Model</strong></a></li>
<li><a href="#5-simple-models-bilinear-and-bicubic"><strong>5. Simple Models (Bilinear and Bicubic)</strong></a></li>
</ul>
</li>
<li><a href="#predict-only-rgbnir-bands-"><strong>Predict only RGBNIR bands</strong> üåç</a></li>
<li><a href="#estimate-the-uncertainty-of-the-model-"><strong>Estimate the uncertainty of the model</strong> üìä</a></li>
<li><a href="#estimate-the-local-attention-map-of-the-model-"><strong>Estimate the Local Attention Map of the model</strong> üìä</a></li>
<li><a href="#use-the-opensr-test-and-supers2-to-analyze-the-hallucination-pixels-"><strong>Use the opensr-test and supers2 to analyze the hallucination pixels</strong> üìä</a></li>
</ul>
</li>
</ul>
<h2 id="overview"><strong>Overview</strong> üìä</h2>
<p><strong>supers2</strong> is a Python package designed to enhance the spatial resolution of Sentinel-2 satellite images to 2.5 meters using a set of neural network models. </p>
<h2 id="installation"><strong>Installation</strong> ‚öôÔ∏è</h2>
<p>Install the latest version from PyPI:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>supers2
</code></pre></div>
<p>From GitHub:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/IPL-UV/supers2.git
</code></pre></div>
<h2 id="how-to-use"><strong>How to use</strong> üõ†Ô∏è</h2>
<h3 id="load-libraries"><strong>Load libraries</strong></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">cubo</span>

<span class="kn">import</span> <span class="nn">supers2</span>
</code></pre></div>
<h3 id="download-sentinel-2-l2a-cube"><strong>Download Sentinel-2 L2A cube</strong></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Create a Sentinel-2 L2A data cube for a specific location and date range</span>
<span class="n">da</span> <span class="o">=</span> <span class="n">cubo</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">lat</span><span class="o">=</span><span class="mf">39.49152740347753</span><span class="p">,</span>
    <span class="n">lon</span><span class="o">=-</span><span class="mf">0.4308725142800361</span><span class="p">,</span>
    <span class="n">collection</span><span class="o">=</span><span class="s2">&quot;sentinel-2-l2a&quot;</span><span class="p">,</span>
    <span class="n">bands</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;B02&quot;</span><span class="p">,</span> <span class="s2">&quot;B03&quot;</span><span class="p">,</span> <span class="s2">&quot;B04&quot;</span><span class="p">,</span> <span class="s2">&quot;B05&quot;</span><span class="p">,</span> <span class="s2">&quot;B06&quot;</span><span class="p">,</span> <span class="s2">&quot;B07&quot;</span><span class="p">,</span> <span class="s2">&quot;B08&quot;</span><span class="p">,</span> <span class="s2">&quot;B8A&quot;</span><span class="p">,</span> <span class="s2">&quot;B11&quot;</span><span class="p">,</span> <span class="s2">&quot;B12&quot;</span><span class="p">],</span>
    <span class="n">start_date</span><span class="o">=</span><span class="s2">&quot;2023-01-01&quot;</span><span class="p">,</span>
    <span class="n">end_date</span><span class="o">=</span><span class="s2">&quot;2023-12-31&quot;</span><span class="p">,</span>
    <span class="n">edge_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">resolution</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="prepare-the-data-cpu-and-gpu-usage"><strong>Prepare the data (CPU and GPU usage)</strong></h3>
<p>When converting a NumPy array to a PyTorch tensor:</p>
<ul>
<li><strong>GPU:</strong> Use <code>.cuda()</code> to transfer the tensor to the GPU if available, improving speed for large datasets or models.</li>
</ul>
<ul>
<li><strong>CPU:</strong> If no GPU is available, PyTorch defaults to the CPU; omit .<code>.cuda()</code>.</li>
</ul>
<p>Here‚Äôs how you can handle both scenarios dynamically:</p>
<p><div class="highlight"><pre><span></span><code><span class="c1"># Check if CUDA is available, use GPU if possible</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</code></pre></div>
Converting data to a PyTorch tensor ensures efficient computation and compatibility, while scaling standardizes pixel values to improve performance.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Convert the data array to NumPy and scale</span>
<span class="n">original_s2_numpy</span> <span class="o">=</span> <span class="p">(</span><span class="n">da</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">/</span> <span class="mi">10_000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="c1"># Create the tensor and move it to the appropriate device (CPU or GPU)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">original_s2_numpy</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<h3 id="default-model-setup"><strong>Default model setup</strong></h3>
<p>The default model is pre-trained for 2.5m resolution but supports 5m and 10m resolutions via the <code>resolution</code> parameter. It uses lightweight CNN architectures for super-resolution and fusion (<code>sr_model_snippet</code>, <code>fusionx2_model_snippet</code>, <code>fusionx4_model_snippet</code>). Models run on CPU or GPU, configurable via <code>device</code>. For more details on the architectures, refer to the <a href="#available-models">section</a>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Set up the model</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">setmodel</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Apply model</span>
<span class="n">superX</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="o">=</span><span class="n">models</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">)</span>
</code></pre></div>
<p>The first plot shows the original Sentinel-2 RGB image (10m resolution). The second plot displays the enhanced version with finer spatial details (2.5m resolution) using a lightweight CNN.</p>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original S2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">superX</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Enhanced Resolution S2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p align="center">
  <img src="assets/images/first_plot.png" width="100%">
</p>

<h3 id="configuring-model"><strong>Configuring Model</strong></h3>
<p>In <strong>supers2</strong>, you can choose from several types of models to enhance the spatial resolution of Sentinel-2 images. Below are the configurations for each model type and their respective <a href="https://github.com/IPL-UV/supers2/releases/tag/v0.1.0">size options</a>. Each model is configured using <code>supers2.setmodel</code>, where the <code>sr_model_snippet</code> argument defines the super-resolution model, and <code>fusionx2_model_snippet</code> and <code>fusionx4_model_snippet</code> correspond to additional fusion models.</p>
<h2 id="available-models"><strong>Available Models:</strong></h2>
<h3 id="1-cnn-models"><strong>1. CNN Models</strong></h3>
<p>CNN-based models are available in the following sizes: <code>lightweight</code>, <code>small</code>, <code>medium</code>, <code>expanded</code>, and <code>large</code>.</p>
<p><div class="highlight"><pre><span></span><code><span class="c1"># Example configuration for a CNN model</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">setmodel</span><span class="p">(</span>
    <span class="n">sr_model_snippet</span><span class="o">=</span><span class="s2">&quot;sr__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx2_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx2__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx4_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx4__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">)</span>

<span class="c1"># Apply spatial resolution enhancement</span>
<span class="n">superX</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">models</span><span class="o">=</span><span class="n">models</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">)</span>
</code></pre></div>
Model size options (replace <code>small</code> with the desired size):</p>
<ul>
<li><code>lightweight</code></li>
<li><code>small</code></li>
<li><code>medium</code></li>
<li><code>expanded</code></li>
<li><code>large</code></li>
</ul>
<p align="center">
  <img src="assets/images/cnns_plot.png" width="100%">
</p>

<h3 id="2-swin-models"><strong>2. SWIN Models</strong></h3>
<p>SWIN models are optimized for varying levels of detail and offer size options: <code>lightweight</code>, <code>small</code>, <code>medium</code>, and <code>expanded</code>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Example configuration for a SWIN model</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">setmodel</span><span class="p">(</span>
    <span class="n">sr_model_snippet</span><span class="o">=</span><span class="s2">&quot;sr__opensrbaseline__swin__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx2_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx2__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx4_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx4__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">)</span>
</code></pre></div>
<p>Available sizes:</p>
<ul>
<li><code>lightweight</code></li>
<li><code>small</code></li>
<li><code>medium</code></li>
<li><code>expanded</code></li>
</ul>
<p align="center">
  <img src="assets/images/swins_plot.png" width="100%">
</p>

<h3 id="3-mamba-models"><strong>3. MAMBA Models</strong></h3>
<p>MAMBA models also come in various sizes, similar to SWIN and CNN: <code>lightweight</code>, <code>small</code>, <code>medium</code>, and <code>expanded</code>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Example configuration for a MAMBA model</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">setmodel</span><span class="p">(</span>
    <span class="n">sr_model_snippet</span><span class="o">=</span><span class="s2">&quot;sr__opensrbaseline__mamba__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx2_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx2__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx4_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx4__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">)</span>
</code></pre></div>
<p>Available sizes:</p>
<ul>
<li><code>lightweight</code></li>
<li><code>small</code></li>
<li><code>medium</code></li>
<li><code>expanded</code></li>
</ul>
<p align="center">
  <img src="assets/images/mambas_plot.png" width="100%">
</p>

<h3 id="4-diffusion-model"><strong>4. Diffusion Model</strong></h3>
<p>The opensrdiffusion model is only available in the <code>large</code> size. This model is suited for deep resolution enhancement without additional configurations.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Configuration for the Diffusion model</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">setmodel</span><span class="p">(</span>
    <span class="n">sr_model_snippet</span><span class="o">=</span><span class="s2">&quot;sr__opensrdiffusion__large__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx2_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx2__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">fusionx4_model_snippet</span><span class="o">=</span><span class="s2">&quot;fusionx4__opensrbaseline__cnn__lightweight__l1&quot;</span><span class="p">,</span>
    <span class="n">resolution</span><span class="o">=</span><span class="s2">&quot;2.5m&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="5-simple-models-bilinear-and-bicubic"><strong>5. Simple Models (Bilinear and Bicubic)</strong></h3>
<p>For fast interpolation, bilinear and bicubic interpolation models can be used. These models do not require complex configurations and are useful for quick evaluations of enhanced resolution.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">supers2.models.simple</span> <span class="kn">import</span> <span class="n">BilinearSR</span><span class="p">,</span> <span class="n">BicubicSR</span>

<span class="c1"># Bilinear Interpolation Model</span>
<span class="n">bilinear_model</span> <span class="o">=</span> <span class="n">BilinearSR</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">super_bilinear</span> <span class="o">=</span> <span class="n">bilinear_model</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Bicubic Interpolation Model</span>
<span class="n">bicubic_model</span> <span class="o">=</span> <span class="n">BicubicSR</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">super_bicubic</span> <span class="o">=</span> <span class="n">bicubic_model</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p align="center">
  <img src="assets/images/bibi.png" width="100%">
</p>

<h2 id="apply-spatial-resolution-enhancement"><strong>Apply spatial resolution enhancement</strong></h2>
<h2 id="predict-only-rgbnir-bands"><strong>Predict only RGBNIR bands</strong> üåç</h2>
<div class="highlight"><pre><span></span><code><span class="n">superX</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">predict_rgbnir</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>
<h2 id="estimate-the-uncertainty-of-the-model"><strong>Estimate the uncertainty of the model</strong> üìä</h2>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">supers2.trained_models</span> <span class="kn">import</span> <span class="n">SRmodels</span>

<span class="c1"># Get the available models</span>
<span class="n">models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">SRmodels</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()[</span><span class="s2">&quot;object&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="c1"># Get only swin transformer models</span>
<span class="n">swin2sr_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="s2">&quot;swin&quot;</span> <span class="ow">in</span> <span class="n">model</span><span class="p">]</span>

<span class="n">map_mean</span><span class="p">,</span> <span class="n">map_std</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">(</span>
    <span class="n">X</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span>
    <span class="n">models</span><span class="o">=</span><span class="n">swin2sr_models</span>
<span class="p">)</span>

<span class="c1"># Visualize the uncertainty</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mean_map</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Mean&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">std_map</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Standard Deviation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p align="center">
  <img src="assets/images/mean.png" width="100%">
</p>

<h3 id="estimate-the-local-attention-map-of-the-model">Estimate the Local Attention Map of the model üìä</h3>
<div class="highlight"><pre><span></span><code><span class="n">kde_map</span><span class="p">,</span> <span class="n">complexity_metric</span><span class="p">,</span> <span class="n">robustness_metric</span><span class="p">,</span> <span class="n">robustness_vector</span> <span class="o">=</span> <span class="n">supers2</span><span class="o">.</span><span class="n">lam</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="c1"># The input tensor</span>
    <span class="n">model</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">srx4</span><span class="p">,</span> <span class="c1"># The SR model</span>
    <span class="n">h</span><span class="o">=</span><span class="mi">240</span><span class="p">,</span> <span class="c1"># The height of the window</span>
    <span class="n">w</span><span class="o">=</span><span class="mi">240</span><span class="p">,</span> <span class="c1"># The width of the window</span>
    <span class="n">window</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="c1"># The window size</span>
    <span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1x&quot;</span><span class="p">,</span> <span class="s2">&quot;2x&quot;</span><span class="p">,</span> <span class="s2">&quot;3x&quot;</span><span class="p">,</span> <span class="s2">&quot;4x&quot;</span><span class="p">,</span> <span class="s2">&quot;5x&quot;</span><span class="p">,</span> <span class="s2">&quot;6x&quot;</span><span class="p">,</span> <span class="s2">&quot;7x&quot;</span><span class="p">,</span> <span class="s2">&quot;8x&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Visualize the results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">kde_map</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Kernel Density Estimation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">robustness_vector</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Robustness Vector&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h2 id="use-the-opensr-test-and-supers2-to-analyze-the-hallucination-pixels">Use the opensr-test and supers2 to analyze the hallucination pixels üìä</h2>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
      
        
        <a href="CONTRIBUTING.html" class="md-footer__link md-footer__link--next" aria-label="Next: Contributing" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Contributing
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": ".", "features": ["navigation.instant", "navigation.tabs", "navigation.top", "navigation.expand", "navigation.indexes", "header.autohide"], "search": "assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.3a4b43e5.min.js"></script>
      
    
  </body>
</html>