{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"A Python package for enhancing the spatial resolution of Sentinel-2 satellite images up to 2.5 meters \ud83d\ude80 GitHub : https://github.com/IPL-UV/supers2 \ud83c\udf10 PyPI : https://pypi.org/project/supers2/ \ud83d\udee0\ufe0f Table of Contents Overview \ud83c\udf0d Installation \u2699\ufe0f How to use \ud83d\udee0\ufe0f Load libraries Download Sentinel-2 L2A cube Prepare the data (CPU and GPU usage) Default model setup Configuring Model Available Models: 1. CNN Models 2. SWIN Models 3. MAMBA Models 4. Diffusion Model 5. Simple Models (Bilinear and Bicubic) Predict only RGBNIR bands Estimate the uncertainty of the model \ud83d\udcca Estimate the Local Attention Map of the model \ud83d\udcca Overview \ud83c\udf0d supers2 is a Python package designed to enhance the spatial resolution of Sentinel-2 satellite images to 2.5 meters using a set of neural network models. Installation \u2699\ufe0f Install the latest version from PyPI: pip install supers2 From GitHub: pip install git+https://github.com/IPL-UV/supers2.git How to use \ud83d\udee0\ufe0f Load libraries import matplotlib.pyplot as plt import numpy as np import torch import cubo import supers2 Download Sentinel-2 L2A cube # Create a Sentinel-2 L2A data cube for a specific location and date range da = cubo . create ( lat = 39.49152740347753 , lon =- 0.4308725142800361 , collection = \"sentinel-2-l2a\" , bands = [ \"B02\" , \"B03\" , \"B04\" , \"B05\" , \"B06\" , \"B07\" , \"B08\" , \"B8A\" , \"B11\" , \"B12\" ], start_date = \"2023-01-01\" , end_date = \"2023-12-31\" , edge_size = 64 , resolution = 10 ) Prepare the data (CPU and GPU usage) When converting a NumPy array to a PyTorch tensor: GPU: Use .cuda() to transfer the tensor to the GPU if available, improving speed for large datasets or models. CPU: If no GPU is available, PyTorch defaults to the CPU; omit .cuda() . Here\u2019s how you can handle both scenarios dynamically: # Check if CUDA is available, use GPU if possible device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) Converting data to a PyTorch tensor ensures efficient computation and compatibility, while scaling standardizes pixel values to improve performance. # Convert the data array to NumPy and scale original_s2_numpy = ( da [ 11 ] . compute () . to_numpy () / 10_000 ) . astype ( \"float32\" ) # Create the tensor and move it to the appropriate device (CPU or GPU) X = torch . from_numpy ( original_s2_numpy ) . float () . to ( device ) Download and Load the model import mlstac # Download the model mlstac . download ( file = \"https://huggingface.co/tacofoundation/supers2/resolve/main/simple_model/mlm.json\" , output_dir = \"models2/CNN_Light_SR\" , ) # Load the model model = mlstac . load ( \"models/supers2_simple_model\" ) . compiled_model () model = model . to ( device ) # Apply model superX = model ( X [ None ]) . squeeze ( 0 ) The first plot shows the original Sentinel-2 RGB image (10m resolution). The second plot displays the enhanced version with finer spatial details (2.5m resolution) using a lightweight CNN. fig , ax = plt . subplots ( 1 , 2 , figsize = ( 10 , 5 )) ax [ 0 ] . imshow ( X [[ 2 , 1 , 0 ]] . permute ( 1 , 2 , 0 ) . cpu () . numpy () * 4 ) ax [ 0 ] . set_title ( \"Original S2\" ) ax [ 1 ] . imshow ( superX [[ 2 , 1 , 0 ]] . permute ( 1 , 2 , 0 ) . cpu () . numpy () * 4 ) ax [ 1 ] . set_title ( \"Enhanced Resolution S2\" ) plt . show () Predict only RGBNIR bands superX = supers2 . predict_rgbnir ( X [[ 2 , 1 , 0 , 6 ]]) Estimate the Local Attention Map of the model \ud83d\udcca kde_map , complexity_metric , robustness_metric , robustness_vector = supers2 . lam ( X = X [[ 2 , 1 , 0 , 6 ]] . cpu (), # The input tensor model = models . srx4 , # The SR model h = 240 , # The height of the window w = 240 , # The width of the window window = 128 , # The window size scales = [ \"1x\" , \"2x\" , \"3x\" , \"4x\" , \"5x\" , \"6x\" , \"7x\" , \"8x\" ] ) # Visualize the results plt . imshow ( kde_map ) plt . title ( \"Kernel Density Estimation\" ) plt . show () plt . plot ( robustness_vector ) plt . title ( \"Robustness Vector\" ) plt . show ()","title":"Index"},{"location":"index.html#_1","text":"A Python package for enhancing the spatial resolution of Sentinel-2 satellite images up to 2.5 meters \ud83d\ude80 GitHub : https://github.com/IPL-UV/supers2 \ud83c\udf10 PyPI : https://pypi.org/project/supers2/ \ud83d\udee0\ufe0f","title":""},{"location":"index.html#table-of-contents","text":"Overview \ud83c\udf0d Installation \u2699\ufe0f How to use \ud83d\udee0\ufe0f Load libraries Download Sentinel-2 L2A cube Prepare the data (CPU and GPU usage) Default model setup Configuring Model Available Models: 1. CNN Models 2. SWIN Models 3. MAMBA Models 4. Diffusion Model 5. Simple Models (Bilinear and Bicubic) Predict only RGBNIR bands Estimate the uncertainty of the model \ud83d\udcca Estimate the Local Attention Map of the model \ud83d\udcca","title":"Table of Contents"},{"location":"index.html#overview","text":"supers2 is a Python package designed to enhance the spatial resolution of Sentinel-2 satellite images to 2.5 meters using a set of neural network models.","title":"Overview \ud83c\udf0d"},{"location":"index.html#installation","text":"Install the latest version from PyPI: pip install supers2 From GitHub: pip install git+https://github.com/IPL-UV/supers2.git","title":"Installation \u2699\ufe0f"},{"location":"index.html#how-to-use","text":"","title":"How to use \ud83d\udee0\ufe0f"},{"location":"index.html#load-libraries","text":"import matplotlib.pyplot as plt import numpy as np import torch import cubo import supers2","title":"Load libraries"},{"location":"index.html#download-sentinel-2-l2a-cube","text":"# Create a Sentinel-2 L2A data cube for a specific location and date range da = cubo . create ( lat = 39.49152740347753 , lon =- 0.4308725142800361 , collection = \"sentinel-2-l2a\" , bands = [ \"B02\" , \"B03\" , \"B04\" , \"B05\" , \"B06\" , \"B07\" , \"B08\" , \"B8A\" , \"B11\" , \"B12\" ], start_date = \"2023-01-01\" , end_date = \"2023-12-31\" , edge_size = 64 , resolution = 10 )","title":"Download Sentinel-2 L2A cube"},{"location":"index.html#prepare-the-data-cpu-and-gpu-usage","text":"When converting a NumPy array to a PyTorch tensor: GPU: Use .cuda() to transfer the tensor to the GPU if available, improving speed for large datasets or models. CPU: If no GPU is available, PyTorch defaults to the CPU; omit .cuda() . Here\u2019s how you can handle both scenarios dynamically: # Check if CUDA is available, use GPU if possible device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) Converting data to a PyTorch tensor ensures efficient computation and compatibility, while scaling standardizes pixel values to improve performance. # Convert the data array to NumPy and scale original_s2_numpy = ( da [ 11 ] . compute () . to_numpy () / 10_000 ) . astype ( \"float32\" ) # Create the tensor and move it to the appropriate device (CPU or GPU) X = torch . from_numpy ( original_s2_numpy ) . float () . to ( device )","title":"Prepare the data (CPU and GPU usage)"},{"location":"index.html#download-and-load-the-model","text":"import mlstac # Download the model mlstac . download ( file = \"https://huggingface.co/tacofoundation/supers2/resolve/main/simple_model/mlm.json\" , output_dir = \"models2/CNN_Light_SR\" , ) # Load the model model = mlstac . load ( \"models/supers2_simple_model\" ) . compiled_model () model = model . to ( device ) # Apply model superX = model ( X [ None ]) . squeeze ( 0 ) The first plot shows the original Sentinel-2 RGB image (10m resolution). The second plot displays the enhanced version with finer spatial details (2.5m resolution) using a lightweight CNN. fig , ax = plt . subplots ( 1 , 2 , figsize = ( 10 , 5 )) ax [ 0 ] . imshow ( X [[ 2 , 1 , 0 ]] . permute ( 1 , 2 , 0 ) . cpu () . numpy () * 4 ) ax [ 0 ] . set_title ( \"Original S2\" ) ax [ 1 ] . imshow ( superX [[ 2 , 1 , 0 ]] . permute ( 1 , 2 , 0 ) . cpu () . numpy () * 4 ) ax [ 1 ] . set_title ( \"Enhanced Resolution S2\" ) plt . show ()","title":"Download and Load the model"},{"location":"index.html#predict-only-rgbnir-bands","text":"superX = supers2 . predict_rgbnir ( X [[ 2 , 1 , 0 , 6 ]])","title":"Predict only RGBNIR bands"},{"location":"index.html#estimate-the-local-attention-map-of-the-model","text":"kde_map , complexity_metric , robustness_metric , robustness_vector = supers2 . lam ( X = X [[ 2 , 1 , 0 , 6 ]] . cpu (), # The input tensor model = models . srx4 , # The SR model h = 240 , # The height of the window w = 240 , # The width of the window window = 128 , # The window size scales = [ \"1x\" , \"2x\" , \"3x\" , \"4x\" , \"5x\" , \"6x\" , \"7x\" , \"8x\" ] ) # Visualize the results plt . imshow ( kde_map ) plt . title ( \"Kernel Density Estimation\" ) plt . show () plt . plot ( robustness_vector ) plt . title ( \"Robustness Vector\" ) plt . show ()","title":"Estimate the Local Attention Map of the model \ud83d\udcca"},{"location":"CHANGELOG.html","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [Unreleased] Added Initial release of SuperS2 with core functionalities for Sentinel-2 data processing. Detailed documentation for installation and basic usage examples. Changed Updated README to include new badges and links. Fixed Fixed minor bugs in the data processing module related to edge cases. [0.0.7] - 2024-10-24 Added First public release with support for enhancing Sentinel-2 spatial resolution to 2.5 meters.","title":"Changelog"},{"location":"CHANGELOG.html#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG.html#unreleased","text":"","title":"[Unreleased]"},{"location":"CHANGELOG.html#added","text":"Initial release of SuperS2 with core functionalities for Sentinel-2 data processing. Detailed documentation for installation and basic usage examples.","title":"Added"},{"location":"CHANGELOG.html#changed","text":"Updated README to include new badges and links.","title":"Changed"},{"location":"CHANGELOG.html#fixed","text":"Fixed minor bugs in the data processing module related to edge cases.","title":"Fixed"},{"location":"CHANGELOG.html#007-2024-10-24","text":"","title":"[0.0.7] - 2024-10-24"},{"location":"CHANGELOG.html#added_1","text":"First public release with support for enhancing Sentinel-2 spatial resolution to 2.5 meters.","title":"Added"},{"location":"CODE_OF_CONDUCT.html","text":"Contributor covenant code of conduct \ud83d\udcdc Our pledge \ud83e\udd1d In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17 Our standards \ud83d\udccf Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54 Our responsibilities \ud83d\udee1\ufe0f Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \ud83c\udf10 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \ud83d\udea8 All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \ud83d\udc4f This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of conduct"},{"location":"CODE_OF_CONDUCT.html#contributor-covenant-code-of-conduct","text":"","title":"Contributor covenant code of conduct \ud83d\udcdc"},{"location":"CODE_OF_CONDUCT.html#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17","title":"Our pledge \ud83e\udd1d"},{"location":"CODE_OF_CONDUCT.html#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54","title":"Our standards \ud83d\udccf"},{"location":"CODE_OF_CONDUCT.html#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our responsibilities \ud83d\udee1\ufe0f"},{"location":"CODE_OF_CONDUCT.html#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope \ud83c\udf10"},{"location":"CODE_OF_CONDUCT.html#enforcement","text":"All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement \ud83d\udea8"},{"location":"CODE_OF_CONDUCT.html#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution \ud83d\udc4f"},{"location":"CONTRIBUTING.html","text":"Contributing \ud83e\udd1d We welcome contributions from the community! Every contribution, no matter how small, is appreciated and credited. Here\u2019s how you can get involved: How to contribute \ud83d\udee0\ufe0f Fork the repository: Start by forking the SuperS2 repository to your GitHub account. \ud83c\udf74 Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone https://github.com/YOUR_GITHUB_USERNAME/supers2.git cd supers2 Create a branch: Create a new branch for your feature or bug fix: git checkout -b name-of-your-bugfix-or-feature Set up the environment: \ud83c\udf31 If you're using pyenv , select a Python version: pyenv local <x.y.z> Install dependencies and activate the environment: poetry install poetry shell Install pre-commit hooks: poetry run pre-commit install Make your changes: \ud83d\udd8b\ufe0f Develop your feature or fix, ensuring you write clear, concise commit messages and include any necessary tests. Check your changes: \u2705 Run formatting checks: make check Run unit tests: make test Optionally, run tests across different Python versions using tox: tox Submit a pull request: \ud83d\ude80 Push your branch to GitHub and submit a pull request to the develop branch of the SuperS2 repository. Ensure your pull request meets these guidelines: Include tests. Update the documentation if your pull request adds functionality. Provide a detailed description of your changes. Types of contributions \ud83d\udce6 Report bugs: \ud83d\udc1b Report bugs by creating an issue on the SuperS2 GitHub repository . Please include your operating system, setup details, and steps to reproduce the bug. Fix bugs: \ud83d\udee0\ufe0f Look for issues tagged with \"bug\" and \"help wanted\" in the repository to start fixing. Implement features: \u2728 Contribute by implementing features tagged with \"enhancement\" and \"help wanted.\" Write documentation: \ud83d\udcda Contribute to the documentation in the official docs, docstrings, or through blog posts and articles. Submit feedback: \ud83d\udcac Propose new features or give feedback by filing an issue on GitHub. Use the SuperS2 GitHub issues page for feedback.","title":"Contributing"},{"location":"CONTRIBUTING.html#contributing","text":"We welcome contributions from the community! Every contribution, no matter how small, is appreciated and credited. Here\u2019s how you can get involved:","title":"Contributing \ud83e\udd1d"},{"location":"CONTRIBUTING.html#how-to-contribute","text":"Fork the repository: Start by forking the SuperS2 repository to your GitHub account. \ud83c\udf74 Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone https://github.com/YOUR_GITHUB_USERNAME/supers2.git cd supers2 Create a branch: Create a new branch for your feature or bug fix: git checkout -b name-of-your-bugfix-or-feature Set up the environment: \ud83c\udf31 If you're using pyenv , select a Python version: pyenv local <x.y.z> Install dependencies and activate the environment: poetry install poetry shell Install pre-commit hooks: poetry run pre-commit install Make your changes: \ud83d\udd8b\ufe0f Develop your feature or fix, ensuring you write clear, concise commit messages and include any necessary tests. Check your changes: \u2705 Run formatting checks: make check Run unit tests: make test Optionally, run tests across different Python versions using tox: tox Submit a pull request: \ud83d\ude80 Push your branch to GitHub and submit a pull request to the develop branch of the SuperS2 repository. Ensure your pull request meets these guidelines: Include tests. Update the documentation if your pull request adds functionality. Provide a detailed description of your changes.","title":"How to contribute \ud83d\udee0\ufe0f"},{"location":"CONTRIBUTING.html#types-of-contributions","text":"Report bugs: \ud83d\udc1b Report bugs by creating an issue on the SuperS2 GitHub repository . Please include your operating system, setup details, and steps to reproduce the bug. Fix bugs: \ud83d\udee0\ufe0f Look for issues tagged with \"bug\" and \"help wanted\" in the repository to start fixing. Implement features: \u2728 Contribute by implementing features tagged with \"enhancement\" and \"help wanted.\" Write documentation: \ud83d\udcda Contribute to the documentation in the official docs, docstrings, or through blog posts and articles. Submit feedback: \ud83d\udcac Propose new features or give feedback by filing an issue on GitHub. Use the SuperS2 GitHub issues page for feedback.","title":"Types of contributions \ud83d\udce6"}]}